{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161d8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an LLM and Setting up Langsmith\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Langchain Tutorial\"\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38b7b0",
   "metadata": {},
   "source": [
    "## Introduction to Tools\n",
    "Tools are a way augment our LLMs with code execution. A tool is simply a function formatted so that our agent can undertstand how to use it, and then execute it. Let's start by creating a few simple tools.\n",
    "\n",
    "We can use the @tool decorator to create an LLM-compatible tool from a standard python function — this function should include a few things for optimal performance:\n",
    "\n",
    "* A docstring describing what the tool does and when it should be used, this will be read by our LLM/agent and used to decide when to use the tool, and also how to use the tool.\n",
    "\n",
    "* Clear parameter names that ideally tell the LLM what each parameter is, if it isn't clear we make sure the docstring explains what the parameter is for and how to use it.\n",
    "\n",
    "* Both parameter and return type annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b46450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f7fee",
   "metadata": {},
   "source": [
    "With the @tool decorator our function is turned into a StructuredTool object, which we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a05304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x000002596B9D9BC0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0762987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ed74af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f973a",
   "metadata": {},
   "source": [
    "When invoking the tool, a JSON string output by the LLM will be parsed into JSON and then consumed as kwargs, similar to the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca60da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e32571",
   "metadata": {},
   "source": [
    "This is then passed into the tool function as kwargs (keyword arguments) as indicated by the ** operator - the ** operator is used to unpack the dictionary into keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf48281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10495881",
   "metadata": {},
   "source": [
    "### Creating an Agent\n",
    "\n",
    "We're going to construct a simple tool calling agent. We will use LangChain Epression Language (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:\n",
    "\n",
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")\n",
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the ChatPromptTemplate with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent will write it's \"notes\" as it is working through multiple internal thought and tool-use steps to produce a final output to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6083077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a Helpful Assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3261d2d",
   "metadata": {},
   "source": [
    "When creating an agent we need to add conversational memory to make the agent remember previous interactions. We'll be using the older ConversationBufferMemory class rather than the newer RunnableWithMessageHistory — the reason being that we will also be using the older create_tool_calling_agent and AgentExecutor method and class.\n",
    "\n",
    "In the 05 chapter we will be using the newer RunnableWithMessageHistory class as we'll be building a custom AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ff63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_3680\\800012107.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd38cdf",
   "metadata": {},
   "source": [
    "Now we will initialize our agent. For that we need:\n",
    "\n",
    "* llm: as already defined <br>\n",
    "* tools: to be defined (just a list of our previously defined tools) <br>\n",
    "* prompt: as already defined <br>\n",
    "* memory: as already defined <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7feec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm,\n",
    "    tools = tools,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf2bd6",
   "metadata": {},
   "source": [
    "Our agent by itself is like one-step of our agent execution loop. So, if we call the agent.invoke method it will get the LLM to generate a single response and go no further, so no tools will be executed, and no next iterations will be performed.\n",
    "\n",
    "We can see this by asking a query that should trigger a tool call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8316b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": []  # agent will append it's internal steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5e1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolAgentAction(tool='multiply', tool_input={'x': 10.7, 'y': 7.68}, log=\"\\nInvoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to calculate 10.7 * 7.68. Use function multiply.', 'tool_calls': [{'id': 'fc_2b78c3ba-99e5-4986-9cdb-053b3db77fb6', 'function': {'arguments': '{\"x\":10.7,\"y\":7.68}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 229, 'total_tokens': 278, 'completion_time': 0.064713115, 'prompt_time': 0.015573745, 'queue_time': 0.246054624, 'total_time': 0.08028686}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_77f8660d1d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a5395bf7-75b1-4d74-a227-ddfe2c458e8a-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10.7, 'y': 7.68}, 'id': 'fc_2b78c3ba-99e5-4986-9cdb-053b3db77fb6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 229, 'output_tokens': 49, 'total_tokens': 278})], tool_call_id='fc_2b78c3ba-99e5-4986-9cdb-053b3db77fb6')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871ad82",
   "metadata": {},
   "source": [
    "Here, we can see the LLM has generated that we should use the multiply tool and the tool input should be {\"x\": 10.7, \"y\": 7.68}. However, the tool is not executed. For that to happen we need an agent execution loop, which will handle the multiple iterations of generation to tool calling to generation, etc.\n",
    "\n",
    "We use the AgentExecutor class to handle the execution loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8343ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    memory = memory, \n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45b927",
   "metadata": {},
   "source": [
    "Now let's try the same query with the executor, note that the intermediate_steps parameter that we added before is no longer needed as the executor handles it internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69ea125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m10.7 × 7.68 = **82.176** (rounded to three decimal places).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 10.7 multiplied by 7.68?',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7\\u202f×\\u202f7.68\\u202f=\\u202f**82.176** (rounded to three decimal places).', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '10.7\\u202f×\\u202f7.68\\u202f=\\u202f**82.176** (rounded to three decimal places).'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57a88f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.17599999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.7*7.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20876d60",
   "metadata": {},
   "source": [
    "Let's test our agent with some memory and tool use. First, we tell it our name, then we will perform a few tool calls, then see if the agent can still recall our name.\n",
    "\n",
    "First, give the agent our name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96787542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mGot it—your name is **Ankur**. Nice to meet you, Ankur! How can I help you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is Ankur',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7\\u202f×\\u202f7.68\\u202f=\\u202f**82.176** (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, James! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Let’s break it down step by step:\\n\\n1. **Multiplication first** (according to order of operations):  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**:  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the power of 3**:  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo, \\\\(\\\\boxed{1331}\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is James.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Got it—your name is **Ankur**. Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Got it—your name is **Ankur**. Nice to meet you, Ankur! How can I help you today?'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"My name is Ankur\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa86ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 4, 'y': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3mLet’s evaluate it step‑by‑step:\n",
      "\n",
      "1. **Multiplication first**  \n",
      "   \\[\n",
      "   4 \\times 2 = 8\n",
      "   \\]\n",
      "\n",
      "2. **Addition and subtraction next**  \n",
      "   \\[\n",
      "   9 + 10 - 8 = 19 - 8 = 11\n",
      "   \\]\n",
      "\n",
      "3. **Raise the result to the 3rd power**  \n",
      "   \\[\n",
      "   11^3 = 11 \\times 11 \\times 11 = 1331\n",
      "   \\]\n",
      "\n",
      "So the value is **1331**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is nine plus 10, minus 4 * 2, to the power of 3',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7\\u202f×\\u202f7.68\\u202f=\\u202f**82.176** (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, James! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Let’s break it down step by step:\\n\\n1. **Multiplication first** (according to order of operations):  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**:  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the power of 3**:  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo, \\\\(\\\\boxed{1331}\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is James.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Got it—your name is **Ankur**. Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Let’s evaluate it step‑by‑step:\\n\\n1. **Multiplication first**  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the 3rd power**  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo the value is **1331**.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Let’s evaluate it step‑by‑step:\\n\\n1. **Multiplication first**  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the 3rd power**  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo the value is **1331**.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is nine plus 10, minus 4 * 2, to the power of 3\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10150acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is **Ankur**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7\\u202f×\\u202f7.68\\u202f=\\u202f**82.176** (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, James! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Let’s break it down step by step:\\n\\n1. **Multiplication first** (according to order of operations):  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**:  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the power of 3**:  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo, \\\\(\\\\boxed{1331}\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is James.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Got it—your name is **Ankur**. Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Let’s evaluate it step‑by‑step:\\n\\n1. **Multiplication first**  \\n   \\\\[\\n   4 \\\\times 2 = 8\\n   \\\\]\\n\\n2. **Addition and subtraction next**  \\n   \\\\[\\n   9 + 10 - 8 = 19 - 8 = 11\\n   \\\\]\\n\\n3. **Raise the result to the 3rd power**  \\n   \\\\[\\n   11^3 = 11 \\\\times 11 \\\\times 11 = 1331\\n   \\\\]\\n\\nSo the value is **1331**.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is **Ankur**.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is **Ankur**.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is my name\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fd29e",
   "metadata": {},
   "source": [
    "### SerpAPI Weather Agent\n",
    "In this example, we'll be using the same agent and executor setup as before, but we'll be adding the SerpAPI service to allow our agent to search the web for information.\n",
    "\n",
    "To use this tool, you need an API key, with the free plan you can use up to 100 searches per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20386551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
