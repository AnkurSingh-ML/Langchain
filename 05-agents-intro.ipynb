{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "161d8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an LLM and Setting up Langsmith\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Langchain Tutorial\"\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a38b7b0",
   "metadata": {},
   "source": [
    "## Introduction to Tools\n",
    "Tools are a way augment our LLMs with code execution. A tool is simply a function formatted so that our agent can undertstand how to use it, and then execute it. Let's start by creating a few simple tools.\n",
    "\n",
    "We can use the @tool decorator to create an LLM-compatible tool from a standard python function — this function should include a few things for optimal performance:\n",
    "\n",
    "* A docstring describing what the tool does and when it should be used, this will be read by our LLM/agent and used to decide when to use the tool, and also how to use the tool.\n",
    "\n",
    "* Clear parameter names that ideally tell the LLM what each parameter is, if it isn't clear we make sure the docstring explains what the parameter is for and how to use it.\n",
    "\n",
    "* Both parameter and return type annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b46450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f7fee",
   "metadata": {},
   "source": [
    "With the @tool decorator our function is turned into a StructuredTool object, which we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a05304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000217037D9260>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0762987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ed74af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55f973a",
   "metadata": {},
   "source": [
    "When invoking the tool, a JSON string output by the LLM will be parsed into JSON and then consumed as kwargs, similar to the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca60da95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e32571",
   "metadata": {},
   "source": [
    "This is then passed into the tool function as kwargs (keyword arguments) as indicated by the ** operator - the ** operator is used to unpack the dictionary into keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf48281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10495881",
   "metadata": {},
   "source": [
    "### Creating an Agent\n",
    "\n",
    "We're going to construct a simple tool calling agent. We will use LangChain Epression Language (LCEL) to construct the agent. We will cover LCEL more in the next chapter, but for now - all we need to know is that our agent will be constructed using syntax and components like so:\n",
    "\n",
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")\n",
    "We need this agent to remember previous interactions within the conversation. To do that, we will use the ChatPromptTemplate with a system message, a placeholder for our chat history, a placeholder for the user query, and finally a placeholder for the agent scratchpad.\n",
    "\n",
    "The agent scratchpad is where the agent will write it's \"notes\" as it is working through multiple internal thought and tool-use steps to produce a final output to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6083077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you are a Helpful Assistant.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),   \n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3261d2d",
   "metadata": {},
   "source": [
    "When creating an agent we need to add conversational memory to make the agent remember previous interactions. We'll be using the older ConversationBufferMemory class rather than the newer RunnableWithMessageHistory — the reason being that we will also be using the older create_tool_calling_agent and AgentExecutor method and class.\n",
    "\n",
    "In the 05 chapter we will be using the newer RunnableWithMessageHistory class as we'll be building a custom AgentExecutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ff63ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankur Singh\\AppData\\Local\\Temp\\ipykernel_25560\\800012107.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key = \"chat_history\",\n",
    "    return_messages= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd38cdf",
   "metadata": {},
   "source": [
    "Now we will initialize our agent. For that we need:\n",
    "\n",
    "* llm: as already defined <br>\n",
    "* tools: to be defined (just a list of our previously defined tools) <br>\n",
    "* prompt: as already defined <br>\n",
    "* memory: as already defined <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7feec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm,\n",
    "    tools = tools,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf2bd6",
   "metadata": {},
   "source": [
    "Our agent by itself is like one-step of our agent execution loop. So, if we call the agent.invoke method it will get the LLM to generate a single response and go no further, so no tools will be executed, and no next iterations will be performed.\n",
    "\n",
    "We can see this by asking a query that should trigger a tool call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8316b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": []  # agent will append it's internal steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d5e1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolAgentAction(tool='multiply', tool_input={'x': 10.7, 'y': 7.68}, log=\"\\nInvoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'reasoning_content': 'We need to compute 10.7 * 7.68. We can do manually or use the multiply function. Use function.', 'tool_calls': [{'id': 'fc_84f16ed6-9ee7-4e0b-ad38-e3b5c88e9c69', 'function': {'arguments': '{\"x\":10.7,\"y\":7.68}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 229, 'total_tokens': 287, 'completion_time': 0.057699392, 'prompt_time': 0.011174739, 'queue_time': 0.042881261, 'total_time': 0.068874131}, 'model_name': 'openai/gpt-oss-20b', 'system_fingerprint': 'fp_3d587a02fb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--2a4cbf10-8149-48ea-ac1d-f7d60ec46096-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10.7, 'y': 7.68}, 'id': 'fc_84f16ed6-9ee7-4e0b-ad38-e3b5c88e9c69', 'type': 'tool_call'}], usage_metadata={'input_tokens': 229, 'output_tokens': 58, 'total_tokens': 287})], tool_call_id='fc_84f16ed6-9ee7-4e0b-ad38-e3b5c88e9c69')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5871ad82",
   "metadata": {},
   "source": [
    "Here, we can see the LLM has generated that we should use the multiply tool and the tool input should be {\"x\": 10.7, \"y\": 7.68}. However, the tool is not executed. For that to happen we need an agent execution loop, which will handle the multiple iterations of generation to tool calling to generation, etc.\n",
    "\n",
    "We use the AgentExecutor class to handle the execution loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8343ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    memory = memory, \n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45b927",
   "metadata": {},
   "source": [
    "Now let's try the same query with the executor, note that the intermediate_steps parameter that we added before is no longer needed as the executor handles it internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ea125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m10.7 × 7.68 = 82.176 (rounded to three decimal places).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 10.7 multiplied by 7.68?',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 × 7.68\\u202f=\\u202f82.176 (rounded to three decimal places).', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '10.7 × 7.68\\u202f=\\u202f82.176 (rounded to three decimal places).'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57a88f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.17599999999999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10.7*7.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20876d60",
   "metadata": {},
   "source": [
    "Let's test our agent with some memory and tool use. First, we tell it our name, then we will perform a few tool calls, then see if the agent can still recall our name.\n",
    "\n",
    "First, give the agent our name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96787542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Ankur! How can I help you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is Ankur',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 × 7.68\\u202f=\\u202f82.176 (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Nice to meet you, Ankur! How can I help you today?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"My name is Ankur\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa86ad71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m9 + 10 − (4 × 2)³  \n",
      "= 19 − 8³  \n",
      "= 19 − 512  \n",
      "= **−493**\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is 9+10-(4x2)^3',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 × 7.68\\u202f=\\u202f82.176 (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is 9+10-(4x2)^3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='9\\u202f+\\u202f10\\u202f−\\u202f(4\\u202f×\\u202f2)³  \\n=\\u202f19\\u202f−\\u202f8³  \\n=\\u202f19\\u202f−\\u202f512  \\n= **−493**', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '9\\u202f+\\u202f10\\u202f−\\u202f(4\\u202f×\\u202f2)³  \\n=\\u202f19\\u202f−\\u202f8³  \\n=\\u202f19\\u202f−\\u202f512  \\n= **−493**'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is 9+10-(4x2)^3\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c76df252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-493"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9+10-(4*2)**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10150acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Ankur.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 × 7.68\\u202f=\\u202f82.176 (rounded to three decimal places).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Ankur', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Ankur! How can I help you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is 9+10-(4x2)^3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='9\\u202f+\\u202f10\\u202f−\\u202f(4\\u202f×\\u202f2)³  \\n=\\u202f19\\u202f−\\u202f8³  \\n=\\u202f19\\u202f−\\u202f512  \\n= **−493**', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Ankur.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Ankur.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is my name\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732fd29e",
   "metadata": {},
   "source": [
    "### SerpAPI Weather Agent\n",
    "In this example, we'll be using the same agent and executor setup as before, but we'll be adding the SerpAPI service to allow our agent to search the web for information.\n",
    "\n",
    "To use this tool, you need an API key, with the free plan you can use up to 250 searches per month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20386551",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf35122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "toolbox = load_tools(tool_names = ['serpapi'], llm = llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e46723",
   "metadata": {},
   "source": [
    "These custom tools can look into your IP address, find out where you are currently, then we will also use a secondary function to get the current date and time, then we will use this information to feed into the SerpAPI to find us the weather pattern in your area and at the time of the function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "766be0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a tool function that will retrieve the location from your ip\n",
    "\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"\n",
    "    Gets the Current Location based on the Ip Address.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            data = (\n",
    "                        f\"Latitude: {latitude},\\n\"\n",
    "                        f\"Longitude: {longitude},\\n\"\n",
    "                        f\"City: {data.get('city','N/A')},\\n\"\n",
    "                        f\"Country: {data.get('country','N/A')}\"\n",
    "            )\n",
    "            print(data)\n",
    "            return data\n",
    "        else:\n",
    "            \"Location could not be determined\"\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b513b09d",
   "metadata": {},
   "source": [
    "We can create our prompt, this time we'll skip the chat_history part as we don't need it. However, you can add it if preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50f4d34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287f367",
   "metadata": {},
   "source": [
    "Now we create our full tools list, our agent, and the agent_executor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aeeb2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolbox + [get_location_from_ip, get_current_datetime]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm,\n",
    "    tools = tools,\n",
    "    prompt = prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent= agent,\n",
    "    tools = tools,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef0a22cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_location_from_ip` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0mLatitude: 28.6519,\n",
      "Longitude: 77.2315,\n",
      "City: Delhi,\n",
      "Country: IN\n",
      "\u001b[33;1m\u001b[1;3mLatitude: 28.6519,\n",
      "Longitude: 77.2315,\n",
      "City: Delhi,\n",
      "Country: IN\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `current weather in Delhi Celsius`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '32', 'unit': 'Celsius', 'precipitation': '0%', 'humidity': '67%', 'wind': '5 km/h', 'location': 'Delhi, India', 'date': 'Tuesday 11:00 AM', 'weather': 'Partly cloudy'}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m2025-09-30 11:03:01\u001b[0m\u001b[32;1m\u001b[1;3m**Current date & time**  \n",
      "2025‑09‑30 11:03 AM (local time)\n",
      "\n",
      "**Weather in Delhi (approximate, as of the latest available data)**  \n",
      "- **Temperature:** 32 °C  \n",
      "- **Condition:** Partly cloudy  \n",
      "- **Humidity:** 67 %  \n",
      "- **Wind:** 5 km/h  \n",
      "- **Precipitation:** 0 %\n",
      "\n",
      "*(All values are from the most recent weather snapshot and may vary slightly by the time you check.)*\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, what is the date and time right now? \"\n",
    "        \"How is the weather where I am? Please give me degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bb59e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `weather Ludhiana Punjab India`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '93', 'unit': 'Fahrenheit', 'precipitation': '0%', 'humidity': '52%', 'wind': '2 mph', 'location': 'Ludhiana, Punjab, India', 'date': 'Tuesday 11:00 AM', 'weather': 'Sunny'}\u001b[0m\u001b[32;1m\u001b[1;3mHere’s the current weather snapshot for **Ludhiana, Punjab, India** (as of the latest update):\n",
      "\n",
      "| Item | Value |\n",
      "|------|-------|\n",
      "| **Temperature** | **≈ 34 °C** (93 °F) |\n",
      "| **Humidity** | 52 % |\n",
      "| **Wind** | 2 mph (≈ 3.2 km/h) |\n",
      "| **Precipitation** | 0 % (no rain) |\n",
      "| **Weather** | Sunny |\n",
      "| **Time** | Tuesday, 11:00 AM (local time) |\n",
      "\n",
      "**Quick note on the conversion:**  \n",
      "93 °F → (93 – 32) × 5/9 ≈ 61 × 5/9 ≈ **33.9 °C**, which rounds to **34 °C**.\n",
      "\n",
      "Feel free to let me know if you’d like more detailed forecasts or historical data!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, How is the weather  n Ludhiana, Punjab, India? Please give me degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6a2b164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here’s the current weather snapshot for **Ludhiana, Punjab, India** (as of the latest update):\n",
       "\n",
       "| Item | Value |\n",
       "|------|-------|\n",
       "| **Temperature** | **≈ 34 °C** (93 °F) |\n",
       "| **Humidity** | 52 % |\n",
       "| **Wind** | 2 mph (≈ 3.2 km/h) |\n",
       "| **Precipitation** | 0 % (no rain) |\n",
       "| **Weather** | Sunny |\n",
       "| **Time** | Tuesday, 11:00 AM (local time) |\n",
       "\n",
       "**Quick note on the conversion:**  \n",
       "93 °F → (93 – 32) × 5/9 ≈ 61 × 5/9 ≈ **33.9 °C**, which rounds to **34 °C**.\n",
       "\n",
       "Feel free to let me know if you’d like more detailed forecasts or historical data!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out[\"output\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda842b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
